{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The **Sequential model** makes the assumption that the network has exactly one input and exactly one output, and that it consists of a linear stack of layers.  \n",
    "\n",
    "But this set of assumptions is too inflexible in a number of cases. Some networks require **several independent inputs** (**Multi-input Models**), others require **multiple outputs**, and some networks have internal branching between layers that makes them look like **graphs of layers** rather than linear stacks of layers.\n",
    "\n",
    "## Introduction to the functional API\n",
    "\n",
    "In the functional API, you directly manipulate tensors, and you use layers as functions that take tensors and return tensors (hence, the name functional API):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32, ))              # a tensor\n",
    "\n",
    "dense = layers.Dense(32, activation='relu')     # a layer is a function\n",
    "\n",
    "output_tensor = dense(input_tensor)             # a layer may be called on a tensor, and it returns a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential vs Functional API\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "# Sequential\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64, )))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Functional equivalent\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)          # the Model class turns an input tensor and output tensor into a model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only part that may seem a bit magical at this point is instantiating a Model object using only an input tensor and an output tensor. Behind the scenes, Keras retrieves every layer involved in going from input_tensor to output_tensor, bringing them together into a graph-like data structure—a Model. Of course, the reason it works is that output_tensor was obtained by repeatedly transforming input_tensor. If you tried to build a model from inputs and outputs that weren’t related, you’d get a RuntimeError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ad090d276832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/araks/anaconda/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/araks/anaconda/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1807\u001b[0m                                 \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                                 \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1810\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "unrelated_input = Input(shape=(32,))\n",
    "bad_model = model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the compiling, evaluating such an instance of Model is the same\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 899us/step - loss: 11.6534\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5413\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.5271\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 11.5182\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5128\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 11.5089\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 11.5068\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.5049\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 11.5028\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 11.5007\n",
      "1000/1000 [==============================] - 0s 82us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "# train\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "# evaluate\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input Models\n",
    "\n",
    "A question-answering model. Such models usually have two inputs: a natural-language question and a test snippet (such as a news article) providing information to be used for answerining the question.  \n",
    "\n",
    "The model must then produce an answer: in the simplest possible setup, this is a one-word answer obtained via a softmax over some predefined vocabulary.\n",
    "\n",
    "Following is an example of how you can build such a model with the functional API. You set up two independent branches, encoding the text input and the question input as representation vectors; then, concatenate these vectors; and finally, add a softmax classifier on top of the concatenated representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Here is a valuable note for anyone reading this book and trying to run the exercised. In the embedding layers below, the book gives the following lines:\n",
    "                                             \n",
    "                                              ...\n",
    "                embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "                                              ...\n",
    "                embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "                \n",
    "While the correct is the following:\n",
    "                            \n",
    "                                              ...\n",
    "                embedded_text = layers.Embedding(text_vocabulary_size)(text_input, 64)\n",
    "                                              ...\n",
    "                embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "                \n",
    "**Where I found the solution**: I found how to fix this with the help of the following page:  https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/ , which says:\n",
    "\n",
    "The embedding must specify 3 arguments:\n",
    "\n",
    "* **input_dim**: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "* **output_dim**: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "* **input_length**: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "So in the book the places of **input_dim** and **output_dim** are switched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,),                                            \n",
    "                   dtype='int32', \n",
    "                   name='text')                                        # the text input is a variable-length sequence of integers. Note that you can optionally name the inputs.\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input) # embeds the inputs into a sequence of vectors of size 64\n",
    "encoded_text = layers.LSTM(32)(embedded_text)                          # encodes the vectors in a single vector via an LSTM\n",
    "\n",
    "question_input = Input(shape=(None,), \n",
    "                       dtype='int32',\n",
    "                      name='question')                                 # Same process (with different layer instance) for the question\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], \n",
    "                                 axis=-1)                              # concatenates the encoded question and encoded text\n",
    "answer = layers.Dense(answer_vocabulary_size,\n",
    "                     activation='softmax')(concatenated)                # Adds a softmax classifier on top\n",
    "\n",
    "model = Model([text_input, question_input], answer)       # At model instantiation, you specify the two inputs and the output\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two possible APIs: feed the model a list of Numpy arrays as inputs, or feed it a dictionary that maps input names to Numpy arrays (if you give names to your inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feeding data to a multi-input model\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                        size=(num_samples, max_length))                   # Generates dummy Numpy data\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                            size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, 1, \n",
    "                           size=(num_samples, answer_vocabulary_size))    # answers are one-hot encoded, not integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Fix the bellow cells later with the help of Keras Documentaion\n",
    "\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12df1f390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting using a list of inputs\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1335d2da0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting using a dictionary of inputs (only if inputs are named)\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "         epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
