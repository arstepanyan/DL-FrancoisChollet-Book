{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load the IMDB dataset\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 13s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "    num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# decode one of these reviews back to English workds\n",
    "word_index = imdb.get_word_index()     # word_index is a dictionary mapping words to an integer index\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])   # note that the indices are offset by 3 because 0,1, and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the integer sequences into a binary matrix\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.    # sets specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to configure the parameters of your optimizer\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to pass a custom loss function or metric function\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Your Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 9s 623us/step - loss: 0.5085 - acc: 0.7815 - val_loss: 0.3796 - val_acc: 0.8684\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.3005 - acc: 0.9045 - val_loss: 0.3003 - val_acc: 0.8899\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 4s 237us/step - loss: 0.2179 - acc: 0.9288 - val_loss: 0.3085 - val_acc: 0.8712\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 4s 245us/step - loss: 0.1750 - acc: 0.9437 - val_loss: 0.2840 - val_acc: 0.8835\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 4s 240us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.2847 - val_acc: 0.8865\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 3s 231us/step - loss: 0.1150 - acc: 0.9651 - val_loss: 0.3148 - val_acc: 0.8773\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 3s 232us/step - loss: 0.0979 - acc: 0.9705 - val_loss: 0.3128 - val_acc: 0.8844\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 3s 233us/step - loss: 0.0807 - acc: 0.9764 - val_loss: 0.3860 - val_acc: 0.8650\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 4s 268us/step - loss: 0.0660 - acc: 0.9821 - val_loss: 0.3634 - val_acc: 0.8784\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 4s 245us/step - loss: 0.0556 - acc: 0.9851 - val_loss: 0.3844 - val_acc: 0.8790\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 4s 239us/step - loss: 0.0447 - acc: 0.9889 - val_loss: 0.4163 - val_acc: 0.8767\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 4s 233us/step - loss: 0.0384 - acc: 0.9913 - val_loss: 0.4509 - val_acc: 0.8696\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 4s 233us/step - loss: 0.0298 - acc: 0.9931 - val_loss: 0.4698 - val_acc: 0.8731\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 4s 253us/step - loss: 0.0246 - acc: 0.9949 - val_loss: 0.5025 - val_acc: 0.8718\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 3s 231us/step - loss: 0.0174 - acc: 0.9981 - val_loss: 0.5464 - val_acc: 0.8679\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 4s 238us/step - loss: 0.0157 - acc: 0.9973 - val_loss: 0.5791 - val_acc: 0.8678\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 4s 246us/step - loss: 0.0097 - acc: 0.9992 - val_loss: 0.6669 - val_acc: 0.8577\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 4s 261us/step - loss: 0.0122 - acc: 0.9971 - val_loss: 0.6463 - val_acc: 0.8688\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 4s 247us/step - loss: 0.0052 - acc: 0.9998 - val_loss: 0.7232 - val_acc: 0.8573\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 4s 266us/step - loss: 0.0099 - acc: 0.9979 - val_loss: 0.7043 - val_acc: 0.8660\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the call to model.fit() returns a History object. This object has a member history, which is a dictionary containing data about everything that happened during training. Let’s look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_acc', 'val_loss', 'loss', 'acc'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1240340f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1230b7a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1248a1cf8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERiUcIQEZFYlDBERCSW/w9OGVqy+Jz8jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12472d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.clf()    # clears the figure, if not in jupiter notebook\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc_values, 'b', label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining a model from scratch (to prevent overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 9s 360us/step - loss: 0.4749 - acc: 0.8217\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 198us/step - loss: 0.2658 - acc: 0.9097 2s - lo\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 166us/step - loss: 0.1983 - acc: 0.9295\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 172us/step - loss: 0.1679 - acc: 0.9400\n",
      "25000/25000 [==============================] - 7s 295us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3233931207084656, 0.87351999999999996]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network to generate predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1385646 ],\n",
       "       [ 0.99970275],\n",
       "       [ 0.29529497],\n",
       "       ..., \n",
       "       [ 0.07222945],\n",
       "       [ 0.04332197],\n",
       "       [ 0.47651461]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Experiments\n",
    "\n",
    "1. Use 1 hidden layer (and see the accuracy increases and the loss decreases)\n",
    "2. Use three hidden layers (better results than with 2 hidden layers, but worse than with 1 hidden layer)\n",
    "3. Use 32 hidden units in each layer (worse than all the previous cases)\n",
    "4. Use 64 hidden units in each layer (slightly better results than 32 hidden units but more time consuming)\n",
    "5. Use 8 hidden units in each layer (the sevond best accuracy after the one hidden unit case, point 1)\n",
    "6. Use mse loss function instead of binary_crossentropy (loss is minimized quite well but the accuracy drops compared to the 1 hidden unit case, point 1)\n",
    "7. Use tanh activation instead of relu (performs worse compared to the point 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 9s 357us/step - loss: 0.4478 - acc: 0.8324\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.2798 - acc: 0.9078\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 162us/step - loss: 0.2214 - acc: 0.9243\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.1878 - acc: 0.9355\n",
      "25000/25000 [==============================] - 8s 306us/step\n"
     ]
    }
   ],
   "source": [
    "# 1. Use 1 hidden layer (and see the accuracy increases and the loss decreases)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27893995951652528, 0.88883999999999996]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 9s 375us/step - loss: 0.4604 - acc: 0.8182\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 6s 257us/step - loss: 0.2503 - acc: 0.9100\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 215us/step - loss: 0.2006 - acc: 0.9262\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.1650 - acc: 0.9408\n",
      "25000/25000 [==============================] - 8s 305us/step\n"
     ]
    }
   ],
   "source": [
    "# 2. Use three hidden layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30755392533302306, 0.88060000000000005]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 10s 397us/step - loss: 0.4273 - acc: 0.8263\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 216us/step - loss: 0.2414 - acc: 0.9115\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 197us/step - loss: 0.1867 - acc: 0.9318\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 195us/step - loss: 0.1594 - acc: 0.9411\n",
      "25000/25000 [==============================] - 9s 361us/step\n"
     ]
    }
   ],
   "source": [
    "# Use 32 hidden units in each layer (worse than all previous cases)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33205159055709838, 0.87263999999999997]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 13s 518us/step - loss: 0.4181 - acc: 0.8154\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 8s 303us/step - loss: 0.2410 - acc: 0.9081\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 7s 268us/step - loss: 0.1840 - acc: 0.9306\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 7s 294us/step - loss: 0.1458 - acc: 0.9465\n",
      "25000/25000 [==============================] - 10s 410us/step\n"
     ]
    }
   ],
   "source": [
    "# 4. Use 64 hidden units in each layer (slightly better results than 32 hidden units but more time consuming)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33436808104991911, 0.87424000000000002]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 8s 327us/step - loss: 0.5327 - acc: 0.7933\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s 186us/step - loss: 0.3335 - acc: 0.8982\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 183us/step - loss: 0.2461 - acc: 0.9188\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 174us/step - loss: 0.2004 - acc: 0.9328\n",
      "25000/25000 [==============================] - 8s 314us/step\n"
     ]
    }
   ],
   "source": [
    "# 5. Use 8 hidden units in each layer (the sevond best accuracy after the one hidden unit case, point 1)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2870811259365082, 0.88539999999999996]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 8s 327us/step - loss: 0.1445 - acc: 0.8236\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 4s 169us/step - loss: 0.0815 - acc: 0.9108\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 165us/step - loss: 0.0634 - acc: 0.9291\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 171us/step - loss: 0.0531 - acc: 0.9406\n",
      "25000/25000 [==============================] - 8s 305us/step\n"
     ]
    }
   ],
   "source": [
    "# Use mse loss function instead of binary_crossentropy \n",
    "# (loss is minimized quite well but the accuracy drops compared to the 1 hidden unit case, point 1)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='mse',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.087684939458370206, 0.88315999999999995]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 8s 325us/step - loss: 0.4422 - acc: 0.8316\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.2720 - acc: 0.9085\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s 166us/step - loss: 0.2135 - acc: 0.9281\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s 168us/step - loss: 0.1796 - acc: 0.9380\n",
      "25000/25000 [==============================] - 8s 321us/step\n"
     ]
    }
   ],
   "source": [
    "# 7. Use tanh activation instead of relu (performs worse compared to the point 1)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28291530010223387, 0.88492000000000004]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Wrapping up\n",
    "\n",
    "* You usually need to do quite a bit of preprocessing on your raw data in order to be able to feed it—as tensors—into a neural network. Sequences of words can be encoded as binary vectors, but there are other encoding options, too.\n",
    "* Stacks of Dense layers with relu activations can solve a wide range of problems (including sentiment classification), and you’ll likely use them frequently.\n",
    "* In a binary classification problem (two output classes), your network should end with a Dense layer with one unit and a sigmoid activation: the output of your network should be a scalar between 0 and 1, encoding a probability.\n",
    "* With such a scalar sigmoid output on a binary classification problem, the loss function you should use is binary_crossentropy.\n",
    "* The rmsprop optimizer is generally a good enough choice, whatever your prob- lem. That’s one less thing for you to worry about.\n",
    "* As they get better on their training data, neural networks eventually start over- fitting and end up obtaining increasingly worse results on data they’ve never seen before. Be sure to always monitor performance on data that is outside of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
